# Capstone Weekly Report

### Date: Sep 03, 2024
- **Topics of Discussion:**
    - **RAG (Retrieval-Augmented Generation):** Understanding the framework and its applications.
    - **LangChain:** Introduction to the library and its role in RAG systems.
    - **Multi-Agent System:** Exploration of how multiple agents can be used to enhance the performance of language models.

- **Action Items:**
    * [&check;] Deep dive into RAG architecture.
    * [&check;] Explore practical use cases for LangChain in RAG.
    * [&check;] Research potential benefits of multi-agent systems in language models.

---

### Date: Sep 10, 2024
- **Topics of Discussion:**
    - **Project Workflow:** Created a general diagram to outline the workflow and architecture.
    - **Dataset Identification:** Found a suitable dataset for the project.
    - **RAG Pipeline:** Built a simple RAG pipeline using basic components.
    - **Model Experimentation:** Tested different models for embeddings and evaluated their effectiveness.
    - **LLM Integration:** Integrated an initial version of a Language Model (LLM) into the pipeline.

![Basic RAG Diagram](Basic_Rag.png)

- **Action Items:**
    * [ ] Refine the project workflow diagram.
    * [ ] Conduct more experiments with different datasets.
    * [ ] Optimize the RAG pipeline with advanced components.
    * [ ] Continue model experimentation for improved embeddings.
    * [ ] Enhance LLM integration based on feedback.

---

### Date: Sep 17, 2024
- **Topics of Discussion:**
    - **Literature Review:** Plan to review relevant research related to RAG and multi-agent systems.
    - **Modular Code Structure:** Need to develop a code structure that supports scalability and testing.
    - **Testing Scripts:** Write and run test scripts to validate code functionality.
    - **Data Acquisition:** Start the process of data collection and cleaning.
    - **Data Exploration:** Continue testing data from various sources for suitability.

- **Action Items:**
    * [ ] Conduct a thorough literature review on RAG and multi-agent systems.
    * [ ] Design and implement a modular code structure.
    * [ ] Develop and run test scripts for the codebase.
    * [ ] Initiate data acquisition and cleaning process.
    * [ ] Evaluate and test data from different sources for the project.

---

### Date: Sep 24, 2024
- **Topics of Discussion:**
    - **Test Folder Structure and Script Actions:** Refining the test folder structure and defining actions for testing vector store and embedding model.
    - **Main Folder Setup:** Creating a main folder to organize the main functions and core components of the project.
    - **PDF Parser Integration:** Integrating a PDF parser into the system to handle document processing.
    - **PDF Download Function:** Developing a Python function to download PDF documents from links mentioned in the data source of BioASQ - Task B.

- **Action Items:**
    * [ ] Refine the folder structure for test scripts, specifically for vector store and embedding model.
    * [ ] Define specific actions and test cases for validating vector store and embedding model functionalities.
    * [ ] Create a main folder for organizing core functions and essential project components.
    * [ ] Integrate a PDF parser into the system for handling document processing.
    * [ ] Develop a Python function to download PDF documents from links mentioned in BioASQ - Task B data source.
    * [ ] Test the PDF download function with a sample link and validate the parser's integration.

---


### Date: Oct 1, 2024
- **Topics of Discussion:**
    - **Score RAG:** Evaluating the performance of the Retrieval-Augmented Generation (RAG) system by scoring its results.
    - **Embedding Models:** Trying different models for embedding to optimize the RAG system's performance.
    - **Chunking Method:** Experimenting with various chunking methods to improve text processing and retrieval efficiency.
    - **RAG Pipeline:** Developing a complete pipeline for RAG with comprehensive testing for all its components.
    - **F-1 Score Evaluation:** Measuring the F-1 score of retrieval at different values of k to evaluate precision and recall in the retrieval process.

- **Action Items:**
    * [ ] Score RAG to assess its overall performance.
    * [ ] Try different models for embedding and compare their results.
    * [ ] Experiment with different chunking methods to optimize the chunk size and method.
    * [ ] Build a complete pipeline for the RAG system, ensuring all components are tested and functioning.
    * [ ] Test and record the F-1 score of retrieval at different values of k (e.g., k=5, 10, 20) to assess retrieval quality.

---


